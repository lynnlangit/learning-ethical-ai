{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Agent Ethics Patterns: Designing Responsible Multi-Agent Systems\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand ethical principles for agentic AI systems\n",
    "- Implement accountability, transparency, and fairness patterns\n",
    "- Design human-in-the-loop (HITL) decision frameworks\n",
    "- Apply patterns to real-world scenarios (healthcare, bioinformatics)\n",
    "\n",
    "**Prerequisites:**\n",
    "- Completed `05-mcp-security-audit.ipynb`\n",
    "- Understanding of agentic AI concepts\n",
    "\n",
    "**Time Required:** ~45 minutes\n",
    "\n",
    "**Context:** This notebook synthesizes ethical patterns applicable to projects like [spatial-mcp](https://github.com/lynnlangit/spatial-mcp) and provides frameworks for responsible agent design.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Agentic AI Ethics Challenge\n",
    "\n",
    "As AI systems move from **assistive** (answering questions) to **agentic** (taking actions), ethical considerations multiply.\n",
    "\n",
    "### Key Differences: Assistive vs Agentic AI\n",
    "\n",
    "| Aspect | Assistive AI | Agentic AI |\n",
    "|--------|--------------|------------|\n",
    "| **Output** | Information, recommendations | Actions, decisions, changes |\n",
    "| **Reversibility** | User decides to act | Actions may be irreversible |\n",
    "| **Accountability** | User responsible | Shared/unclear responsibility |\n",
    "| **Scope** | Single interaction | Multi-step, multi-system |\n",
    "| **Autonomy** | None | Partial to full |\n",
    "\n",
    "### Ethical Principles for Agentic AI\n",
    "\n",
    "Based on IEEE, NIST AI RMF, and EU AI Act:\n",
    "\n",
    "1. **Transparency**: Users understand what the agent can and will do\n",
    "2. **Accountability**: Clear responsibility chain for agent actions\n",
    "3. **Fairness**: Actions don't discriminate or cause unequal harm\n",
    "4. **Safety**: Agents cannot cause unacceptable harm\n",
    "5. **Human Control**: Meaningful human oversight is maintained\n",
    "6. **Privacy**: Agent respects data protection principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Dict, Any, Callable\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "print(\"âœ… Ethics pattern library loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pattern 1: Graduated Autonomy\n",
    "\n",
    "Not all actions require the same level of oversight. Implement **graduated autonomy** based on action risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutonomyLevel(Enum):\n",
    "    \"\"\"Levels of agent autonomy based on action risk.\"\"\"\n",
    "    \n",
    "    # Level 1: Full autonomy - agent acts without asking\n",
    "    FULL = \"full\"\n",
    "    \n",
    "    # Level 2: Notify - agent acts and informs user\n",
    "    NOTIFY = \"notify\"\n",
    "    \n",
    "    # Level 3: Confirm - agent proposes, user approves\n",
    "    CONFIRM = \"confirm\"\n",
    "    \n",
    "    # Level 4: Supervised - human reviews each step\n",
    "    SUPERVISED = \"supervised\"\n",
    "    \n",
    "    # Level 5: Disabled - action not permitted\n",
    "    DISABLED = \"disabled\"\n",
    "\n",
    "@dataclass\n",
    "class ActionPolicy:\n",
    "    \"\"\"Policy defining autonomy level for an action type.\"\"\"\n",
    "    action_type: str\n",
    "    autonomy_level: AutonomyLevel\n",
    "    requires_justification: bool\n",
    "    max_impact_scope: str  # e.g., \"single_file\", \"patient_record\", \"workflow\"\n",
    "    cooldown_seconds: int = 0  # Minimum time between actions\n",
    "    daily_limit: Optional[int] = None\n",
    "\n",
    "# Example policies for a bioinformatics agent (spatial-mcp style)\n",
    "BIOINFORMATICS_POLICIES = {\n",
    "    # Read operations - full autonomy\n",
    "    \"read_file\": ActionPolicy(\n",
    "        action_type=\"read_file\",\n",
    "        autonomy_level=AutonomyLevel.FULL,\n",
    "        requires_justification=False,\n",
    "        max_impact_scope=\"single_file\"\n",
    "    ),\n",
    "    \"query_database\": ActionPolicy(\n",
    "        action_type=\"query_database\",\n",
    "        autonomy_level=AutonomyLevel.FULL,\n",
    "        requires_justification=False,\n",
    "        max_impact_scope=\"query_result\"\n",
    "    ),\n",
    "    \"search_pubmed\": ActionPolicy(\n",
    "        action_type=\"search_pubmed\",\n",
    "        autonomy_level=AutonomyLevel.FULL,\n",
    "        requires_justification=False,\n",
    "        max_impact_scope=\"search_result\"\n",
    "    ),\n",
    "    \n",
    "    # Analysis operations - notify\n",
    "    \"run_analysis\": ActionPolicy(\n",
    "        action_type=\"run_analysis\",\n",
    "        autonomy_level=AutonomyLevel.NOTIFY,\n",
    "        requires_justification=True,\n",
    "        max_impact_scope=\"analysis_output\",\n",
    "        cooldown_seconds=60\n",
    "    ),\n",
    "    \n",
    "    # Write operations - confirm required\n",
    "    \"write_results\": ActionPolicy(\n",
    "        action_type=\"write_results\",\n",
    "        autonomy_level=AutonomyLevel.CONFIRM,\n",
    "        requires_justification=True,\n",
    "        max_impact_scope=\"output_file\"\n",
    "    ),\n",
    "    \"modify_patient_data\": ActionPolicy(\n",
    "        action_type=\"modify_patient_data\",\n",
    "        autonomy_level=AutonomyLevel.SUPERVISED,\n",
    "        requires_justification=True,\n",
    "        max_impact_scope=\"patient_record\"\n",
    "    ),\n",
    "    \n",
    "    # Workflow operations - supervised\n",
    "    \"submit_workflow\": ActionPolicy(\n",
    "        action_type=\"submit_workflow\",\n",
    "        autonomy_level=AutonomyLevel.SUPERVISED,\n",
    "        requires_justification=True,\n",
    "        max_impact_scope=\"compute_cluster\",\n",
    "        daily_limit=5\n",
    "    ),\n",
    "    \n",
    "    # Dangerous operations - disabled\n",
    "    \"delete_data\": ActionPolicy(\n",
    "        action_type=\"delete_data\",\n",
    "        autonomy_level=AutonomyLevel.DISABLED,\n",
    "        requires_justification=True,\n",
    "        max_impact_scope=\"any\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def check_action_permitted(action_type: str, policies: dict) -> tuple:\n",
    "    \"\"\"Check if an action is permitted and at what autonomy level.\"\"\"\n",
    "    policy = policies.get(action_type)\n",
    "    \n",
    "    if policy is None:\n",
    "        # Unknown action - default to supervised\n",
    "        return AutonomyLevel.SUPERVISED, \"Unknown action type - defaulting to supervised\"\n",
    "    \n",
    "    if policy.autonomy_level == AutonomyLevel.DISABLED:\n",
    "        return AutonomyLevel.DISABLED, f\"Action '{action_type}' is not permitted\"\n",
    "    \n",
    "    return policy.autonomy_level, f\"Action permitted at {policy.autonomy_level.value} level\"\n",
    "\n",
    "# Test the policy checker\n",
    "print(\"ğŸ” Graduated Autonomy Policy Checks:\")\n",
    "print(\"=\" * 50)\n",
    "for action in [\"read_file\", \"write_results\", \"submit_workflow\", \"delete_data\", \"unknown_action\"]:\n",
    "    level, message = check_action_permitted(action, BIOINFORMATICS_POLICIES)\n",
    "    print(f\"  {action}: {level.value} - {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pattern 2: Explainable Decision Chain\n",
    "\n",
    "Every agent decision should be traceable and explainable. Implement a **decision chain** that captures reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionStep:\n",
    "    \"\"\"A single step in an agent's decision chain.\"\"\"\n",
    "    step_id: str\n",
    "    timestamp: str\n",
    "    action: str\n",
    "    reasoning: str\n",
    "    inputs: Dict[str, Any]\n",
    "    outputs: Dict[str, Any]\n",
    "    confidence: float  # 0.0 to 1.0\n",
    "    alternatives_considered: List[str]\n",
    "    human_override: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class DecisionChain:\n",
    "    \"\"\"Complete decision chain for an agent task.\"\"\"\n",
    "    chain_id: str\n",
    "    user_request: str\n",
    "    started_at: str\n",
    "    steps: List[DecisionStep] = field(default_factory=list)\n",
    "    final_outcome: Optional[str] = None\n",
    "    completed_at: Optional[str] = None\n",
    "    \n",
    "    def add_step(self, action: str, reasoning: str, inputs: dict, \n",
    "                 outputs: dict, confidence: float, alternatives: list) -> DecisionStep:\n",
    "        \"\"\"Add a step to the decision chain.\"\"\"\n",
    "        step = DecisionStep(\n",
    "            step_id=f\"{self.chain_id}-step-{len(self.steps)+1}\",\n",
    "            timestamp=datetime.utcnow().isoformat() + \"Z\",\n",
    "            action=action,\n",
    "            reasoning=reasoning,\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "            confidence=confidence,\n",
    "            alternatives_considered=alternatives\n",
    "        )\n",
    "        self.steps.append(step)\n",
    "        return step\n",
    "    \n",
    "    def explain(self) -> str:\n",
    "        \"\"\"Generate human-readable explanation of the decision chain.\"\"\"\n",
    "        explanation = [f\"Decision Chain: {self.chain_id}\"]\n",
    "        explanation.append(f\"User Request: {self.user_request}\")\n",
    "        explanation.append(f\"Started: {self.started_at}\")\n",
    "        explanation.append(\"\\nDecision Steps:\")\n",
    "        \n",
    "        for i, step in enumerate(self.steps, 1):\n",
    "            explanation.append(f\"\\n  Step {i}: {step.action}\")\n",
    "            explanation.append(f\"    Reasoning: {step.reasoning}\")\n",
    "            explanation.append(f\"    Confidence: {step.confidence:.0%}\")\n",
    "            if step.alternatives_considered:\n",
    "                explanation.append(f\"    Alternatives: {', '.join(step.alternatives_considered)}\")\n",
    "            if step.human_override:\n",
    "                explanation.append(f\"    âš ï¸ Human Override: {step.human_override}\")\n",
    "        \n",
    "        if self.final_outcome:\n",
    "            explanation.append(f\"\\nFinal Outcome: {self.final_outcome}\")\n",
    "        \n",
    "        return \"\\n\".join(explanation)\n",
    "\n",
    "# Example: Decision chain for a bioinformatics query\n",
    "chain = DecisionChain(\n",
    "    chain_id=\"dc-2026-001\",\n",
    "    user_request=\"Find genes associated with ovarian cancer and analyze their expression in patient PAT001\",\n",
    "    started_at=datetime.utcnow().isoformat() + \"Z\"\n",
    ")\n",
    "\n",
    "# Step 1: Literature search\n",
    "chain.add_step(\n",
    "    action=\"search_pubmed\",\n",
    "    reasoning=\"User asked about ovarian cancer genes. PubMed is the best source for established gene associations.\",\n",
    "    inputs={\"query\": \"ovarian cancer associated genes BRCA\", \"max_results\": 20},\n",
    "    outputs={\"articles_found\": 20, \"key_genes\": [\"BRCA1\", \"BRCA2\", \"TP53\", \"KRAS\"]},\n",
    "    confidence=0.95,\n",
    "    alternatives=[\"query_tcga\", \"search_clinvar\"]\n",
    ")\n",
    "\n",
    "# Step 2: Patient data retrieval\n",
    "chain.add_step(\n",
    "    action=\"query_patient_expression\",\n",
    "    reasoning=\"Need to check expression of identified genes in patient PAT001's data.\",\n",
    "    inputs={\"patient_id\": \"PAT001\", \"genes\": [\"BRCA1\", \"BRCA2\", \"TP53\", \"KRAS\"]},\n",
    "    outputs={\"expression_data\": \"retrieved\", \"samples\": 3},\n",
    "    confidence=0.90,\n",
    "    alternatives=[\"aggregate_cohort_data\"]\n",
    ")\n",
    "\n",
    "# Step 3: Analysis (would normally require confirmation)\n",
    "step3 = chain.add_step(\n",
    "    action=\"run_differential_expression\",\n",
    "    reasoning=\"Differential expression analysis will identify significant changes in gene expression.\",\n",
    "    inputs={\"method\": \"DESeq2\", \"comparison\": \"tumor_vs_normal\"},\n",
    "    outputs={\"significant_genes\": 47, \"top_gene\": \"BRCA1\"},\n",
    "    confidence=0.85,\n",
    "    alternatives=[\"edgeR\", \"limma\"]\n",
    ")\n",
    "\n",
    "chain.final_outcome = \"Identified 47 differentially expressed genes, with BRCA1 showing highest significance.\"\n",
    "chain.completed_at = datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "print(chain.explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pattern 3: Ethical Guardrails Framework\n",
    "\n",
    "Define explicit ethical constraints that the agent must respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EthicalConstraint:\n",
    "    \"\"\"An ethical constraint the agent must respect.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    principle: str  # Which ethical principle this supports\n",
    "    check_function: Callable[[Dict], bool]\n",
    "    violation_response: str\n",
    "    severity: str  # \"blocking\", \"warning\", \"advisory\"\n",
    "\n",
    "def check_patient_consent(context: dict) -> bool:\n",
    "    \"\"\"Check if patient consent exists for the action.\"\"\"\n",
    "    patient_id = context.get(\"patient_id\")\n",
    "    action_type = context.get(\"action_type\")\n",
    "    \n",
    "    # In production, this would check a consent database\n",
    "    # For demo, assume consent exists for research use\n",
    "    if action_type in [\"research_analysis\", \"aggregate_statistics\"]:\n",
    "        return True\n",
    "    if action_type in [\"share_externally\", \"publish_individually\"]:\n",
    "        return False  # Would need explicit consent\n",
    "    return True\n",
    "\n",
    "def check_data_minimization(context: dict) -> bool:\n",
    "    \"\"\"Check if only necessary data is being accessed.\"\"\"\n",
    "    requested_fields = set(context.get(\"requested_fields\", []))\n",
    "    necessary_fields = set(context.get(\"necessary_fields\", []))\n",
    "    \n",
    "    # Fail if requesting more than necessary\n",
    "    excess_fields = requested_fields - necessary_fields\n",
    "    return len(excess_fields) == 0\n",
    "\n",
    "def check_bias_risk(context: dict) -> bool:\n",
    "    \"\"\"Check if action might introduce or amplify bias.\"\"\"\n",
    "    # Check for demographic-based filtering that could introduce bias\n",
    "    filters = context.get(\"filters\", {})\n",
    "    sensitive_attributes = [\"race\", \"ethnicity\", \"gender\", \"socioeconomic\"]\n",
    "    \n",
    "    for attr in sensitive_attributes:\n",
    "        if attr in filters:\n",
    "            return False  # Potential bias risk\n",
    "    return True\n",
    "\n",
    "# Define ethical constraints for a healthcare AI agent\n",
    "HEALTHCARE_ETHICAL_CONSTRAINTS = [\n",
    "    EthicalConstraint(\n",
    "        name=\"patient_consent\",\n",
    "        description=\"Patient must have consented to the specific use of their data\",\n",
    "        principle=\"Privacy & Autonomy\",\n",
    "        check_function=check_patient_consent,\n",
    "        violation_response=\"Cannot proceed without patient consent for this action\",\n",
    "        severity=\"blocking\"\n",
    "    ),\n",
    "    EthicalConstraint(\n",
    "        name=\"data_minimization\",\n",
    "        description=\"Only access data that is necessary for the task\",\n",
    "        principle=\"Privacy\",\n",
    "        check_function=check_data_minimization,\n",
    "        violation_response=\"Requesting more data than necessary - please justify or reduce scope\",\n",
    "        severity=\"warning\"\n",
    "    ),\n",
    "    EthicalConstraint(\n",
    "        name=\"bias_prevention\",\n",
    "        description=\"Actions should not introduce or amplify demographic bias\",\n",
    "        principle=\"Fairness\",\n",
    "        check_function=check_bias_risk,\n",
    "        violation_response=\"This action may introduce demographic bias - review required\",\n",
    "        severity=\"warning\"\n",
    "    )\n",
    "]\n",
    "\n",
    "def evaluate_ethical_constraints(context: dict, constraints: list) -> dict:\n",
    "    \"\"\"Evaluate all ethical constraints for a given context.\"\"\"\n",
    "    results = {\n",
    "        \"all_passed\": True,\n",
    "        \"blocking_violations\": [],\n",
    "        \"warnings\": [],\n",
    "        \"details\": []\n",
    "    }\n",
    "    \n",
    "    for constraint in constraints:\n",
    "        passed = constraint.check_function(context)\n",
    "        \n",
    "        result = {\n",
    "            \"constraint\": constraint.name,\n",
    "            \"principle\": constraint.principle,\n",
    "            \"passed\": passed,\n",
    "            \"severity\": constraint.severity\n",
    "        }\n",
    "        \n",
    "        if not passed:\n",
    "            result[\"violation_response\"] = constraint.violation_response\n",
    "            \n",
    "            if constraint.severity == \"blocking\":\n",
    "                results[\"all_passed\"] = False\n",
    "                results[\"blocking_violations\"].append(constraint.name)\n",
    "            elif constraint.severity == \"warning\":\n",
    "                results[\"warnings\"].append(constraint.name)\n",
    "        \n",
    "        results[\"details\"].append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test ethical constraints\n",
    "test_context = {\n",
    "    \"patient_id\": \"PAT001\",\n",
    "    \"action_type\": \"research_analysis\",\n",
    "    \"requested_fields\": [\"gene_expression\", \"diagnosis\", \"age\"],\n",
    "    \"necessary_fields\": [\"gene_expression\", \"diagnosis\"],\n",
    "    \"filters\": {}\n",
    "}\n",
    "\n",
    "results = evaluate_ethical_constraints(test_context, HEALTHCARE_ETHICAL_CONSTRAINTS)\n",
    "\n",
    "print(\"ğŸ” Ethical Constraint Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"All Passed: {results['all_passed']}\")\n",
    "print(f\"Blocking Violations: {results['blocking_violations']}\")\n",
    "print(f\"Warnings: {results['warnings']}\")\n",
    "print(\"\\nDetails:\")\n",
    "for detail in results[\"details\"]:\n",
    "    status = \"âœ…\" if detail[\"passed\"] else \"âŒ\"\n",
    "    print(f\"  {status} {detail['constraint']} ({detail['principle']}): {'Passed' if detail['passed'] else detail.get('violation_response', 'Failed')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pattern 4: Stakeholder Impact Assessment\n",
    "\n",
    "Before taking significant actions, assess impact on all stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Stakeholder:\n",
    "    \"\"\"A stakeholder who may be affected by agent actions.\"\"\"\n",
    "    name: str\n",
    "    type: str  # \"individual\", \"group\", \"organization\", \"society\"\n",
    "    interests: List[str]\n",
    "    vulnerability_level: str  # \"high\", \"medium\", \"low\"\n",
    "\n",
    "@dataclass\n",
    "class ImpactAssessment:\n",
    "    \"\"\"Assessment of action impact on a stakeholder.\"\"\"\n",
    "    stakeholder: Stakeholder\n",
    "    impact_type: str  # \"positive\", \"negative\", \"neutral\"\n",
    "    impact_magnitude: str  # \"high\", \"medium\", \"low\"\n",
    "    description: str\n",
    "    mitigation: Optional[str] = None\n",
    "\n",
    "# Define stakeholders for a healthcare AI system\n",
    "HEALTHCARE_STAKEHOLDERS = [\n",
    "    Stakeholder(\n",
    "        name=\"Patient\",\n",
    "        type=\"individual\",\n",
    "        interests=[\"privacy\", \"accurate diagnosis\", \"appropriate treatment\", \"autonomy\"],\n",
    "        vulnerability_level=\"high\"\n",
    "    ),\n",
    "    Stakeholder(\n",
    "        name=\"Healthcare Provider\",\n",
    "        type=\"individual\",\n",
    "        interests=[\"clinical accuracy\", \"efficiency\", \"liability protection\", \"patient trust\"],\n",
    "        vulnerability_level=\"medium\"\n",
    "    ),\n",
    "    Stakeholder(\n",
    "        name=\"Healthcare Organization\",\n",
    "        type=\"organization\",\n",
    "        interests=[\"regulatory compliance\", \"reputation\", \"efficiency\", \"cost management\"],\n",
    "        vulnerability_level=\"medium\"\n",
    "    ),\n",
    "    Stakeholder(\n",
    "        name=\"Research Community\",\n",
    "        type=\"group\",\n",
    "        interests=[\"data access\", \"reproducibility\", \"scientific advancement\"],\n",
    "        vulnerability_level=\"low\"\n",
    "    ),\n",
    "    Stakeholder(\n",
    "        name=\"Underrepresented Populations\",\n",
    "        type=\"group\",\n",
    "        interests=[\"equitable treatment\", \"representation in training data\", \"fair outcomes\"],\n",
    "        vulnerability_level=\"high\"\n",
    "    )\n",
    "]\n",
    "\n",
    "def assess_action_impact(action: str, action_details: dict, \n",
    "                         stakeholders: list) -> List[ImpactAssessment]:\n",
    "    \"\"\"Assess the impact of an action on all stakeholders.\"\"\"\n",
    "    assessments = []\n",
    "    \n",
    "    # This would be more sophisticated in production\n",
    "    # Here we demonstrate the pattern with simple heuristics\n",
    "    \n",
    "    for stakeholder in stakeholders:\n",
    "        if action == \"train_model_on_patient_data\":\n",
    "            if stakeholder.name == \"Patient\":\n",
    "                assessments.append(ImpactAssessment(\n",
    "                    stakeholder=stakeholder,\n",
    "                    impact_type=\"negative\" if \"privacy\" in stakeholder.interests else \"neutral\",\n",
    "                    impact_magnitude=\"medium\",\n",
    "                    description=\"Patient data used for training may have privacy implications\",\n",
    "                    mitigation=\"Use differential privacy, obtain informed consent\"\n",
    "                ))\n",
    "            elif stakeholder.name == \"Underrepresented Populations\":\n",
    "                assessments.append(ImpactAssessment(\n",
    "                    stakeholder=stakeholder,\n",
    "                    impact_type=\"negative\",\n",
    "                    impact_magnitude=\"high\" if action_details.get(\"diverse_data\", False) == False else \"low\",\n",
    "                    description=\"Model trained on non-diverse data may perform poorly for underrepresented groups\",\n",
    "                    mitigation=\"Ensure diverse representation in training data, test for bias\"\n",
    "                ))\n",
    "            elif stakeholder.name == \"Research Community\":\n",
    "                assessments.append(ImpactAssessment(\n",
    "                    stakeholder=stakeholder,\n",
    "                    impact_type=\"positive\",\n",
    "                    impact_magnitude=\"medium\",\n",
    "                    description=\"New model may advance research capabilities\",\n",
    "                    mitigation=None\n",
    "                ))\n",
    "    \n",
    "    return assessments\n",
    "\n",
    "# Example impact assessment\n",
    "action_details = {\n",
    "    \"data_sources\": [\"hospital_a\", \"hospital_b\"],\n",
    "    \"diverse_data\": False,\n",
    "    \"sample_size\": 10000\n",
    "}\n",
    "\n",
    "impacts = assess_action_impact(\"train_model_on_patient_data\", action_details, HEALTHCARE_STAKEHOLDERS)\n",
    "\n",
    "print(\"ğŸ“Š Stakeholder Impact Assessment:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Action: train_model_on_patient_data\")\n",
    "print(\"\\nImpacts:\")\n",
    "for impact in impacts:\n",
    "    icon = \"ğŸŸ¢\" if impact.impact_type == \"positive\" else \"ğŸ”´\" if impact.impact_type == \"negative\" else \"âšª\"\n",
    "    print(f\"\\n  {icon} {impact.stakeholder.name}\")\n",
    "    print(f\"     Type: {impact.impact_type}, Magnitude: {impact.impact_magnitude}\")\n",
    "    print(f\"     Description: {impact.description}\")\n",
    "    if impact.mitigation:\n",
    "        print(f\"     Mitigation: {impact.mitigation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pattern 5: Reversibility and Recovery\n",
    "\n",
    "Design agents to prefer reversible actions and maintain recovery capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reversibility(Enum):\n",
    "    \"\"\"Reversibility classification for agent actions.\"\"\"\n",
    "    FULLY_REVERSIBLE = \"fully_reversible\"      # Can undo completely\n",
    "    PARTIALLY_REVERSIBLE = \"partially_reversible\"  # Can partially undo\n",
    "    IRREVERSIBLE = \"irreversible\"              # Cannot undo\n",
    "\n",
    "@dataclass\n",
    "class ActionCheckpoint:\n",
    "    \"\"\"Checkpoint for potential rollback.\"\"\"\n",
    "    checkpoint_id: str\n",
    "    timestamp: str\n",
    "    action: str\n",
    "    state_before: Dict[str, Any]\n",
    "    reversibility: Reversibility\n",
    "    rollback_procedure: Optional[str] = None\n",
    "\n",
    "class RecoveryManager:\n",
    "    \"\"\"Manages checkpoints and recovery for agent actions.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_checkpoints: int = 100):\n",
    "        self.checkpoints: List[ActionCheckpoint] = []\n",
    "        self.max_checkpoints = max_checkpoints\n",
    "    \n",
    "    def create_checkpoint(self, action: str, state: dict, \n",
    "                          reversibility: Reversibility,\n",
    "                          rollback_procedure: str = None) -> ActionCheckpoint:\n",
    "        \"\"\"Create a checkpoint before taking an action.\"\"\"\n",
    "        checkpoint = ActionCheckpoint(\n",
    "            checkpoint_id=f\"ckpt-{len(self.checkpoints)+1}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}\",\n",
    "            timestamp=datetime.utcnow().isoformat() + \"Z\",\n",
    "            action=action,\n",
    "            state_before=state.copy(),\n",
    "            reversibility=reversibility,\n",
    "            rollback_procedure=rollback_procedure\n",
    "        )\n",
    "        \n",
    "        self.checkpoints.append(checkpoint)\n",
    "        \n",
    "        # Trim old checkpoints\n",
    "        if len(self.checkpoints) > self.max_checkpoints:\n",
    "            self.checkpoints = self.checkpoints[-self.max_checkpoints:]\n",
    "        \n",
    "        return checkpoint\n",
    "    \n",
    "    def can_rollback(self, checkpoint_id: str) -> bool:\n",
    "        \"\"\"Check if rollback is possible for a checkpoint.\"\"\"\n",
    "        for ckpt in self.checkpoints:\n",
    "            if ckpt.checkpoint_id == checkpoint_id:\n",
    "                return ckpt.reversibility != Reversibility.IRREVERSIBLE\n",
    "        return False\n",
    "    \n",
    "    def get_rollback_plan(self, checkpoint_id: str) -> Optional[str]:\n",
    "        \"\"\"Get the rollback procedure for a checkpoint.\"\"\"\n",
    "        for ckpt in self.checkpoints:\n",
    "            if ckpt.checkpoint_id == checkpoint_id:\n",
    "                if ckpt.reversibility == Reversibility.IRREVERSIBLE:\n",
    "                    return \"âš ï¸ This action cannot be rolled back.\"\n",
    "                return ckpt.rollback_procedure or \"Restore state_before values\"\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "recovery = RecoveryManager()\n",
    "\n",
    "# Checkpoint before a file write (reversible)\n",
    "ckpt1 = recovery.create_checkpoint(\n",
    "    action=\"write_analysis_results\",\n",
    "    state={\"file_exists\": False, \"path\": \"/results/analysis_001.csv\"},\n",
    "    reversibility=Reversibility.FULLY_REVERSIBLE,\n",
    "    rollback_procedure=\"Delete file at /results/analysis_001.csv\"\n",
    ")\n",
    "\n",
    "# Checkpoint before a database update (partially reversible)\n",
    "ckpt2 = recovery.create_checkpoint(\n",
    "    action=\"update_patient_record\",\n",
    "    state={\"patient_id\": \"PAT001\", \"previous_status\": \"active\"},\n",
    "    reversibility=Reversibility.PARTIALLY_REVERSIBLE,\n",
    "    rollback_procedure=\"Restore previous_status to 'active'; audit log entry cannot be removed\"\n",
    ")\n",
    "\n",
    "# Checkpoint before sending an email (irreversible)\n",
    "ckpt3 = recovery.create_checkpoint(\n",
    "    action=\"send_notification_email\",\n",
    "    state={\"recipient\": \"doctor@hospital.org\", \"subject\": \"New results available\"},\n",
    "    reversibility=Reversibility.IRREVERSIBLE,\n",
    "    rollback_procedure=None\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Recovery Manager Status:\")\n",
    "print(\"=\" * 50)\n",
    "for ckpt in recovery.checkpoints:\n",
    "    can_rollback = recovery.can_rollback(ckpt.checkpoint_id)\n",
    "    icon = \"âœ…\" if can_rollback else \"âš ï¸\"\n",
    "    print(f\"\\n{icon} {ckpt.checkpoint_id}\")\n",
    "    print(f\"   Action: {ckpt.action}\")\n",
    "    print(f\"   Reversibility: {ckpt.reversibility.value}\")\n",
    "    print(f\"   Rollback: {recovery.get_rollback_plan(ckpt.checkpoint_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pattern 6: Ethics Review Gate\n",
    "\n",
    "For high-stakes actions, implement a formal ethics review gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EthicsReviewRequest:\n",
    "    \"\"\"Request for ethics review of an agent action.\"\"\"\n",
    "    request_id: str\n",
    "    action: str\n",
    "    context: Dict[str, Any]\n",
    "    risk_assessment: str\n",
    "    stakeholder_impacts: List[str]\n",
    "    requested_by: str  # agent_id\n",
    "    requested_at: str\n",
    "    urgency: str  # \"immediate\", \"standard\", \"low\"\n",
    "    \n",
    "@dataclass\n",
    "class EthicsReviewDecision:\n",
    "    \"\"\"Decision from ethics review.\"\"\"\n",
    "    request_id: str\n",
    "    decision: str  # \"approved\", \"rejected\", \"approved_with_conditions\"\n",
    "    reviewer: str\n",
    "    reviewed_at: str\n",
    "    conditions: Optional[List[str]] = None\n",
    "    rationale: str = \"\"\n",
    "\n",
    "class EthicsReviewGate:\n",
    "    \"\"\"Gate for ethics review of high-stakes actions.\"\"\"\n",
    "    \n",
    "    # Actions that always require ethics review\n",
    "    MANDATORY_REVIEW_ACTIONS = [\n",
    "        \"train_model_on_patient_data\",\n",
    "        \"share_data_externally\",\n",
    "        \"automated_clinical_decision\",\n",
    "        \"modify_treatment_recommendation\",\n",
    "        \"delete_patient_data\"\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pending_reviews: List[EthicsReviewRequest] = []\n",
    "        self.completed_reviews: List[EthicsReviewDecision] = []\n",
    "    \n",
    "    def requires_review(self, action: str, context: dict) -> bool:\n",
    "        \"\"\"Check if an action requires ethics review.\"\"\"\n",
    "        # Mandatory review for certain actions\n",
    "        if action in self.MANDATORY_REVIEW_ACTIONS:\n",
    "            return True\n",
    "        \n",
    "        # Check for high-risk indicators\n",
    "        if context.get(\"affects_vulnerable_population\", False):\n",
    "            return True\n",
    "        if context.get(\"involves_minors\", False):\n",
    "            return True\n",
    "        if context.get(\"potential_for_discrimination\", False):\n",
    "            return True\n",
    "        if context.get(\"large_scale_impact\", False):\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def submit_for_review(self, action: str, context: dict, \n",
    "                          agent_id: str, urgency: str = \"standard\") -> EthicsReviewRequest:\n",
    "        \"\"\"Submit an action for ethics review.\"\"\"\n",
    "        request = EthicsReviewRequest(\n",
    "            request_id=f\"er-{len(self.pending_reviews)+1}-{datetime.utcnow().strftime('%Y%m%d')}\",\n",
    "            action=action,\n",
    "            context=context,\n",
    "            risk_assessment=self._assess_risk(action, context),\n",
    "            stakeholder_impacts=self._identify_stakeholder_impacts(action, context),\n",
    "            requested_by=agent_id,\n",
    "            requested_at=datetime.utcnow().isoformat() + \"Z\",\n",
    "            urgency=urgency\n",
    "        )\n",
    "        self.pending_reviews.append(request)\n",
    "        return request\n",
    "    \n",
    "    def _assess_risk(self, action: str, context: dict) -> str:\n",
    "        \"\"\"Assess risk level of the action.\"\"\"\n",
    "        if action in self.MANDATORY_REVIEW_ACTIONS:\n",
    "            return \"HIGH - Mandatory review action\"\n",
    "        if context.get(\"affects_vulnerable_population\"):\n",
    "            return \"HIGH - Affects vulnerable population\"\n",
    "        return \"MEDIUM - Standard review\"\n",
    "    \n",
    "    def _identify_stakeholder_impacts(self, action: str, context: dict) -> List[str]:\n",
    "        \"\"\"Identify potential stakeholder impacts.\"\"\"\n",
    "        impacts = []\n",
    "        if \"patient\" in action.lower() or context.get(\"involves_patients\"):\n",
    "            impacts.append(\"Patients: Privacy and autonomy concerns\")\n",
    "        if context.get(\"affects_vulnerable_population\"):\n",
    "            impacts.append(\"Vulnerable populations: Potential for disproportionate impact\")\n",
    "        if \"share\" in action.lower() or \"external\" in action.lower():\n",
    "            impacts.append(\"Organization: Compliance and liability considerations\")\n",
    "        return impacts\n",
    "\n",
    "# Example usage\n",
    "ethics_gate = EthicsReviewGate()\n",
    "\n",
    "# Test if actions require review\n",
    "test_actions = [\n",
    "    (\"search_pubmed\", {}),\n",
    "    (\"train_model_on_patient_data\", {\"involves_patients\": True}),\n",
    "    (\"run_analysis\", {\"affects_vulnerable_population\": True}),\n",
    "    (\"share_data_externally\", {\"recipient\": \"research_partner\"})\n",
    "]\n",
    "\n",
    "print(\"ğŸ” Ethics Review Gate Assessment:\")\n",
    "print(\"=\" * 50)\n",
    "for action, context in test_actions:\n",
    "    requires = ethics_gate.requires_review(action, context)\n",
    "    icon = \"âš ï¸ REVIEW REQUIRED\" if requires else \"âœ… No review needed\"\n",
    "    print(f\"\\n{action}: {icon}\")\n",
    "    \n",
    "    if requires:\n",
    "        request = ethics_gate.submit_for_review(action, context, \"agent-001\")\n",
    "        print(f\"  Request ID: {request.request_id}\")\n",
    "        print(f\"  Risk: {request.risk_assessment}\")\n",
    "        for impact in request.stakeholder_impacts:\n",
    "            print(f\"  Impact: {impact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Applying Patterns to spatial-mcp\n",
    "\n",
    "Here's how these patterns apply to the [spatial-mcp](https://github.com/lynnlangit/spatial-mcp) project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPATIAL_MCP_ETHICS_CONFIG = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              SPATIAL-MCP ETHICS PATTERN APPLICATION                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  MCP SERVER: fgbio                                                          â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 1 (Graduated Autonomy)                                         â”‚\n",
    "â”‚  â”‚   â€¢ read_bam: FULL autonomy                                              â”‚\n",
    "â”‚  â”‚   â€¢ run_analysis: NOTIFY                                                 â”‚\n",
    "â”‚  â”‚   â€¢ write_output: CONFIRM                                                â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 5 (Reversibility)                                              â”‚\n",
    "â”‚  â”‚   â€¢ Create checkpoints before file writes                                â”‚\n",
    "â”‚  â”‚   â€¢ Maintain rollback capability for output files                        â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  MCP SERVER: mockepic (Patient Data)                                        â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 3 (Ethical Constraints)                                        â”‚\n",
    "â”‚  â”‚   â€¢ Data minimization enforced                                           â”‚\n",
    "â”‚  â”‚   â€¢ PHI access logged                                                    â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 4 (Stakeholder Impact)                                         â”‚\n",
    "â”‚  â”‚   â€¢ Patient privacy assessment for each query                            â”‚\n",
    "â”‚  â”‚   â€¢ Vulnerable population checks                                         â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 6 (Ethics Review)                                              â”‚\n",
    "â”‚  â”‚   â€¢ Required for: data sharing, bulk exports                             â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  MCP SERVER: seqera (Workflow Execution)                                    â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 1 (Graduated Autonomy)                                         â”‚\n",
    "â”‚  â”‚   â€¢ list_workflows: FULL                                                 â”‚\n",
    "â”‚  â”‚   â€¢ submit_workflow: SUPERVISED                                          â”‚\n",
    "â”‚  â”‚   â€¢ cancel_workflow: CONFIRM                                             â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 2 (Decision Chain)                                             â”‚\n",
    "â”‚  â”‚   â€¢ Full trace of workflow submission rationale                          â”‚\n",
    "â”‚  â”‚   â€¢ Cost and resource impact documented                                  â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 5 (Reversibility)                                              â”‚\n",
    "â”‚  â”‚   â€¢ Workflow cancellation supported                                      â”‚\n",
    "â”‚  â”‚   â€¢ Output cleanup on failure                                            â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  MCP SERVER: pubmed                                                         â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 1 (Graduated Autonomy)                                         â”‚\n",
    "â”‚  â”‚   â€¢ All operations: FULL (read-only, public data)                        â”‚\n",
    "â”‚  â”œâ”€â”€ Pattern 2 (Decision Chain)                                             â”‚\n",
    "â”‚  â”‚   â€¢ Log search queries for reproducibility                               â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  CROSS-CUTTING CONCERNS                                                     â”‚\n",
    "â”‚  â”œâ”€â”€ All servers implement audit logging                                    â”‚\n",
    "â”‚  â”œâ”€â”€ Decision chains stored for compliance review                           â”‚\n",
    "â”‚  â”œâ”€â”€ Ethics review gate for patient data operations                         â”‚\n",
    "â”‚  â””â”€â”€ Stakeholder impact assessment for new analysis types                   â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "\n",
    "print(SPATIAL_MCP_ETHICS_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Summary: Ethics Pattern Checklist\n",
    "\n",
    "Use this checklist when designing any agentic AI system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETHICS_DESIGN_CHECKLIST = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    AGENTIC AI ETHICS DESIGN CHECKLIST                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ GRADUATED AUTONOMY                                                       â”‚\n",
    "â”‚    â€¢ Classified all actions by risk level                                   â”‚\n",
    "â”‚    â€¢ Defined autonomy levels (full â†’ disabled)                              â”‚\n",
    "â”‚    â€¢ Implemented HITL gates for high-risk actions                           â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ EXPLAINABLE DECISIONS                                                    â”‚\n",
    "â”‚    â€¢ Decision chains captured for all significant actions                   â”‚\n",
    "â”‚    â€¢ Reasoning documented at each step                                      â”‚\n",
    "â”‚    â€¢ Alternatives considered are recorded                                   â”‚\n",
    "â”‚    â€¢ Human overrides tracked                                                â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ ETHICAL CONSTRAINTS                                                      â”‚\n",
    "â”‚    â€¢ Consent requirements defined                                           â”‚\n",
    "â”‚    â€¢ Data minimization enforced                                             â”‚\n",
    "â”‚    â€¢ Bias prevention checks implemented                                     â”‚\n",
    "â”‚    â€¢ Blocking vs warning severity defined                                   â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ STAKEHOLDER IMPACT                                                       â”‚\n",
    "â”‚    â€¢ All stakeholders identified                                            â”‚\n",
    "â”‚    â€¢ Vulnerable populations explicitly considered                           â”‚\n",
    "â”‚    â€¢ Impact assessment for significant actions                              â”‚\n",
    "â”‚    â€¢ Mitigation strategies documented                                       â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ REVERSIBILITY & RECOVERY                                                 â”‚\n",
    "â”‚    â€¢ Actions classified by reversibility                                    â”‚\n",
    "â”‚    â€¢ Checkpoints created before state changes                               â”‚\n",
    "â”‚    â€¢ Rollback procedures defined                                            â”‚\n",
    "â”‚    â€¢ Irreversible actions require extra confirmation                        â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ ETHICS REVIEW GATE                                                       â”‚\n",
    "â”‚    â€¢ Mandatory review actions defined                                       â”‚\n",
    "â”‚    â€¢ Review request process implemented                                     â”‚\n",
    "â”‚    â€¢ Escalation path for urgent decisions                                   â”‚\n",
    "â”‚    â€¢ Review decisions logged                                                â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â˜ COMPLIANCE & AUDIT                                                       â”‚\n",
    "â”‚    â€¢ All actions logged with context                                        â”‚\n",
    "â”‚    â€¢ Audit trail supports compliance requirements                           â”‚\n",
    "â”‚    â€¢ Regular ethics audits scheduled                                        â”‚\n",
    "â”‚    â€¢ Incident response plan documented                                      â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "\n",
    "print(ETHICS_DESIGN_CHECKLIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Key Takeaways\n",
    "\n",
    "| Pattern | Purpose | When to Use |\n",
    "|---------|---------|-------------|\n",
    "| Graduated Autonomy | Match oversight to risk | All agentic systems |\n",
    "| Decision Chain | Enable accountability | Significant decisions |\n",
    "| Ethical Constraints | Enforce principles | Data/privacy-sensitive actions |\n",
    "| Stakeholder Impact | Prevent unintended harm | High-impact actions |\n",
    "| Reversibility | Enable recovery | State-changing actions |\n",
    "| Ethics Review Gate | Formal oversight | High-stakes decisions |\n",
    "\n",
    "## ğŸ”— Resources\n",
    "\n",
    "- [spatial-mcp Project](https://github.com/lynnlangit/spatial-mcp) - Reference implementation\n",
    "- [IEEE Ethically Aligned Design](https://ethicsinaction.ieee.org/)\n",
    "- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)\n",
    "- [EU AI Act](https://artificialintelligenceact.eu/)\n",
    "- [Anthropic Responsible Scaling Policy](https://www.anthropic.com/news/anthropics-responsible-scaling-policy)\n",
    "\n",
    "## ğŸ¯ Next Steps\n",
    "\n",
    "You've now completed the full examples series! Consider:\n",
    "\n",
    "1. **Integrate patterns into your own projects** - Apply these patterns to your MCP implementations\n",
    "2. **Contribute to the repo** - Add domain-specific examples or improve existing ones\n",
    "3. **Stay current** - Follow the evolving regulatory landscape (EU AI Act, NIST updates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
